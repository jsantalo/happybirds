{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from dateutil import parser\n",
    "import dateutil\n",
    "import matplotlib.dates as dates\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.dates as mdates\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/tweets_public_ES.csv\", encoding = \"utf-16\", sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['date'] = [dateutil.parser.parse(x) for x in data['tweet_created']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tweets' distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = subplots()\n",
    "\n",
    "data.groupby([pd.Grouper(key='date', freq='D'), 'airline_sentiment']).size().unstack().plot(figsize=(15,7), \\\n",
    "  color = ['#FF860C', 'grey', '#0080FF'], linewidth = 2, ax = ax)\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval = 3))\n",
    "ax.set_ylabel(\"number of tweets\")\n",
    "\"\"\"\n",
    "savefig(\"sentiment_timeline_ES.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import *\n",
    "fig, ax = subplots()\n",
    "data.groupby([pd.Grouper(key='date', freq='D'), 'airline_sentiment']).size().unstack().plot(figsize=(15,7), \\\n",
    "  color = ['#FF860C', 'grey', '#0080FF'], linewidth = 2, ax = ax)\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval = 3))\n",
    "ax.set_ylabel(\"number of tweets\")\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.legend(loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "\"\"\"\n",
    "savefig(\"sentiment_timeline_ES.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_whitespace(x):\n",
    "    \"\"\"\n",
    "    Helper function to remove any blank space from a string\n",
    "    x: a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove spaces inside of the string\n",
    "        x = \" \".join(x.split())\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('spanish')\n",
    "\n",
    "# found these stopwords below handy to take out\n",
    "new_stoplist = ['https', 'el', 'de', 'co', 'lo', 'que', 'la', 'en', 'con', 'por', 'los', 'un', 'del', 'n', 't']\n",
    "\n",
    "for i in new_stoplist:\n",
    "    stop.append(i)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: x.lower())\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub\\\n",
    "                              (\"https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+\", \"url\", x)) # convert links to \"url\"\n",
    "df[\"text_2\"] = df[\"text\"].apply(lambda x: re.sub(\"[^a-zA-Z@]\", \" \", x)) # remove all but alphabetical keeping \"@\"\n",
    "\n",
    "df[\"text_2\"] = \\\n",
    "    df['text_2'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) # remove stopwords\n",
    "df[\"text_2\"] = df[\"text_2\"].apply(remove_whitespace)  # remove extra whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index('date') \n",
    "\n",
    "dec14_neg = df[(df.index.get_level_values(0) >= '2017-12-14 00:00:00') & \n",
    "   (df.index.get_level_values(0) <= '2017-12-14 23:59:00') & \n",
    "   (df.airline_sentiment == \"negative\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ignore = set(('https', 'el', 'de', 'co', 'lo', 'que', 'la', 'en', 'con', 'por', 'los', 'un', 'del', 'n'))\n",
    "fwc = {'stopwords': STOPWORDS | ignore, **wc}\n",
    "text = dec14_neg['text_2'].str.lower().to_string()\n",
    "wordcloud = WordCloud(**fwc, background_color='white',\n",
    "                        #color_func = 'magma',\n",
    "                        colormap = \"inferno_r\",).generate(''.join(text))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\"\"\"\n",
    "savefig(\"ES_2017_12_14_neg.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None, dpi=500)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec14_neg.text_2.str.split(expand=True).stack().value_counts().head(10) # see most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## airline sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index('date') \n",
    "\n",
    "def create_columns_with_airlines(df):\n",
    "    # a list curated based on word frequencies and search terms for data download\n",
    "    list_of_airlines = [\"iberia\", \"ryanair\", \"jetblue\", \"spanair\", \"vueling\", \"norwegian\", \"aireuropa\"]\n",
    "    for airline in list_of_airlines: \n",
    "        df[airline] = \"\"\n",
    "        for index,row in df.iterrows():\n",
    "            if airline in row[\"text\"].lower():\n",
    "                df.set_value(index,airline,1)\n",
    "            else:\n",
    "                df.set_value(index,airline,0)\n",
    "    df[airline] = df[airline].astype(str).astype(int)\n",
    "create_columns_with_airlines(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines_day = df.resample('D').apply({'iberia':'sum', 'spanair': 'sum', 'jetblue': 'sum',\\\n",
    "                                       'vueling': 'sum', 'ryanair': 'sum', 'norwegian': 'sum', 'aireuropa': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines_day_unstacked = airlines_day.unstack().reset_index()\n",
    "airlines_day_unstacked.rename(columns={'level_0': 'airline', 0: 'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove zeros\n",
    "airlines_day_unstacked = airlines_day_unstacked[(airlines_day_unstacked != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines_day_unstacked[\"date\"] = airlines_day_unstacked[\"date\"].apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pivot = airlines_day_unstacked.pivot(\"airline\", \"date\", \"count\")\n",
    "pivot = pivot.fillna(0) # to remove Nones\n",
    "sns.set(rc={'figure.figsize':(15,5)})\n",
    "cmap1 = mpl.colors.ListedColormap(sns.color_palette(\"pink_r\", 100))\n",
    "\n",
    "ax = sns.heatmap(pivot, cmap = cmap1)\n",
    "#ax = sns.heatmap(pivot)\n",
    "#ax.set_ylabel(\"airline mentions\")\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "plt.yticks(fontsize=14)\n",
    "\"\"\"\n",
    "plt.savefig(\"airlines_by_day_ES.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None, dpi = 600)\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select only that day\n",
    "mask = (df['tweet_created'] > \"Thu Dec 14 00:00:00 +0000 2017\") & (df['tweet_created'] <= \"Thu Dec 14 23:59:59 +0000 2017\")\n",
    "data_2017_12_14 = df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2017_12_14_iberia = data_2017_12_14.loc[data_2017_12_14.text_2.str.contains(\"iberia\", case = False, na = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "data_2017_12_14_iberia[\"text_2\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2017_12_14_iberia_negative = (data_2017_12_14_iberia.\\\n",
    "                                   loc[data_2017_12_14_iberia.airline_sentiment == \"negative\"])[\"text_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2017_12_14_iberia_negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2017_12_14_iberia_negative.reset_index().text_2.str.split(expand=True).stack().value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_wordcloud(text): # optionally add: stopwords=STOPWORDS and change the arg below\n",
    "    ignore = set(('https', 'el', 'de', 'co', 'lo', 'que', 'la', 'en', 'con', 'por', 'los', 'un', 'del', 'iberia', 'vuelo'))\n",
    "    fwc = {'stopwords': STOPWORDS | ignore, **wc}\n",
    "    wordcloud = WordCloud(#relative_scaling = 0.75\n",
    "                        **fwc,\n",
    "                        background_color='white',\n",
    "                        colormap = \"inferno_r\"\n",
    "                        #width=800, height=400\n",
    "                          ).generate(text)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    # EN_2015_02_23_neg_american_tweets_without_strings_american_flights\n",
    "    \"\"\"\n",
    "    savefig(\"ES_2017_12_14_neg_iberia.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None, dpi=500)\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "generate_wordcloud(data_2017_12_14_iberia_negative.str.lower().str.strip().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# why tweets contain \"felicidades\"?\n",
    "(data_2017_12_14[data_2017_12_14['text'].str.contains(\"felicidades\", case = False)])[\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# why tweets contain \"instantaneamente\"?\n",
    "(data_2017_12_14[data_2017_12_14['text'].str.contains(\"instantaneamente\", case = False)])[\"text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Iberia or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iberia_o_no(df):\n",
    "    df[\"iberia_o_no\"] = \"\"\n",
    "    for index,row in df.iterrows():\n",
    "        if \"iberia\" in row[\"text_3\"].lower():\n",
    "              df.set_value(index,'iberia_o_no',\"iberia\")\n",
    "        else:\n",
    "              df.set_value(index,'iberia_o_no',\"not_iberia\")\n",
    "iberia_o_no(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_iberia = df.loc[df.iberia_o_no == \"iberia\"]\n",
    "df_NOT_iberia = df.loc[df.iberia_o_no != \"iberia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iberia_values = df_iberia.text_3.str.split(expand=True).stack().value_counts()\\\n",
    "    .reset_index().rename(columns={'index': 'iberia_word', 0:'iberia_value'})\n",
    "\n",
    "NOT_iberia_values = df_NOT_iberia.text_3.str.split(expand=True).stack().value_counts()\\\n",
    "    .reset_index().rename(columns={'index': 'NOT_iberia_word', 0:'NOT_iberia_value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not iberia\n",
    "NOT_iberia_merged = pd.merge(NOT_iberia_values, iberia_values, \\\n",
    "                             left_on='NOT_iberia_word', right_on='iberia_word', how = 'left')\n",
    "del NOT_iberia_merged[\"iberia_word\"]\n",
    "NOT_iberia_merged[\"NOT_iberia_value_norm\"] = \\\n",
    "    (NOT_iberia_merged[\"NOT_iberia_value\"] - NOT_iberia_merged[\"NOT_iberia_value\"].min()) / \\\n",
    "    (NOT_iberia_merged[\"NOT_iberia_value\"].max()-NOT_iberia_merged[\"NOT_iberia_value\"].min())\n",
    "\n",
    "NOT_iberia_merged[\"iberia_value_norm\"] = \\\n",
    "    (NOT_iberia_merged[\"iberia_value\"] - NOT_iberia_merged[\"iberia_value\"].min()) / \\\n",
    "    (NOT_iberia_merged[\"iberia_value\"].max()-NOT_iberia_merged[\"iberia_value\"].min())\n",
    "del NOT_iberia_merged[\"NOT_iberia_value\"]\n",
    "del NOT_iberia_merged[\"iberia_value\"]\n",
    "NOT_iberia_merged.rename(columns={'NOT_iberia_word': 'word', \\\n",
    "                                  'NOT_iberia_value_norm': 'all_other', 'iberia_value_norm': 'Iberia'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "x=NOT_iberia_merged[\"all_other\"].head(10)\n",
    "y=NOT_iberia_merged[\"Iberia\"].head(10)\n",
    "label=NOT_iberia_merged[\"word\"].head(10)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "xy_line = (0, 1)\n",
    "ax.scatter(x, y, c = \"red\", alpha = 0.5)\n",
    "ax.set_xlabel(\"all other airlines\")\n",
    "ax.set_ylabel(\"Iberia\")\n",
    "\n",
    "for i, txt in enumerate(label):\n",
    "    ax.annotate(txt, (x[i],y[i]))\n",
    "\n",
    "ax.plot(xy_line, c = \"grey\")\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\"\"\"\n",
    "plt.savefig(\"non_Iberia_words_scatter_top10.png\", \n",
    "        transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None, format=None, dpi=700)\n",
    "\"\"\"\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iberia\n",
    "iberia_merged = pd.merge(iberia_values, NOT_iberia_values, left_on = \"iberia_word\",\\\n",
    "                          right_on = \"NOT_iberia_word\", how = \"left\")\n",
    "del iberia_merged[\"NOT_iberia_word\"]\n",
    "iberia_merged[\"iberia_value_norm\"] = \\\n",
    "    (iberia_merged[\"iberia_value\"] - iberia_merged[\"iberia_value\"].min()) / \\\n",
    "    (iberia_merged[\"iberia_value\"].max()-iberia_merged[\"iberia_value\"].min())\n",
    "\n",
    "iberia_merged[\"NOT_iberia_value_norm\"] = \\\n",
    "    (iberia_merged[\"NOT_iberia_value\"] - iberia_merged[\"NOT_iberia_value\"].min()) / \\\n",
    "    (iberia_merged[\"NOT_iberia_value\"].max()-iberia_merged[\"NOT_iberia_value\"].min())\n",
    "del iberia_merged[\"iberia_value\"]\n",
    "del iberia_merged[\"NOT_iberia_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=iberia_merged[\"iberia_value_norm\"].head(10)\n",
    "y=iberia_merged[\"NOT_iberia_value_norm\"].head(10)\n",
    "label=iberia_merged[\"iberia_word\"].head(10)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "xy_line = (0, 1)\n",
    "ax.scatter(x, y, c = \"red\", alpha = 0.5)\n",
    "ax.set_xlabel(\"Iberia\")\n",
    "ax.set_ylabel(\"all other airlines\")\n",
    "\n",
    "for i, txt in enumerate(label):\n",
    "    ax.annotate(txt, (x[i],y[i]))\n",
    "\n",
    "ax.plot(xy_line, c = \"grey\")\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\"\"\"\n",
    "plt.savefig(\"Iberia_words_scatter_top10.png\", \n",
    "        transparent=True, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None, format=None, dpi=700)\n",
    "\"\"\"\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top words by airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_ocurrences(x):\n",
    "    airlines = [\"aireuropa\", \"iberia\", \"jetblue\", \"norwegian\", \"ryanair\", \"spanair\", \"vueling\"]\n",
    "    for airline in airlines:\n",
    "        print(airline + \": \"+ str((len(df[df[\"text_3\"].str.contains(airline, case = False)]))))\n",
    "number_ocurrences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iberia = df[df[\"text_3\"].str.contains(\"iberia\", case = False)]\n",
    "iberia.text_3.str.split(expand=True).stack().value_counts().head(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ryanair = df[df[\"text_3\"].str.contains(\"ryanair\", case = False)]\n",
    "ryanair.text_3.str.split(expand=True).stack().value_counts().head(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vueling = df[df[\"text_3\"].str.contains(\"vueling\", case = False)]\n",
    "vueling.text_3.str.split(expand=True).stack().value_counts().head(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spanair = df[df[\"text_3\"].str.contains(\"spanair\", case = False)]\n",
    "spanair.text_3.str.split(expand=True).stack().value_counts().head(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
