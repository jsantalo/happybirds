{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from dateutil import parser\n",
    "import dateutil\n",
    "import matplotlib.dates as dates\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.dates as mdates\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/tweets_public_ES.csv\", encoding = \"utf-16\", sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset='text')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['date'] = [dateutil.parser.parse(x) for x in data['tweet_created']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = subplots()\n",
    "\n",
    "data.groupby([pd.Grouper(key='date', freq='D'), 'airline_sentiment']).size().unstack().plot(figsize=(15,7), \\\n",
    "  color = ['#FF860C', 'grey', '#0080FF'], linewidth = 2, ax = ax)\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval = 3))\n",
    "ax.set_ylabel(\"number of tweets\")\n",
    "\"\"\"\n",
    "savefig(\"sentiment_timeline_ES.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import *\n",
    "fig, ax = subplots()\n",
    "data.groupby([pd.Grouper(key='date', freq='D'), 'airline_sentiment']).size().unstack().plot(figsize=(15,7), \\\n",
    "  color = ['#FF860C', 'grey', '#0080FF'], linewidth = 2, ax = ax)\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval = 3))\n",
    "ax.set_ylabel(\"number of tweets\")\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.legend(loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "\"\"\"\n",
    "savefig(\"sentiment_timeline_ES.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_whitespace(x):\n",
    "    \"\"\"\n",
    "    Helper function to remove any blank space from a string\n",
    "    x: a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove spaces inside of the string\n",
    "        x = \" \".join(x.split())\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('spanish')\n",
    "\n",
    "# found these stopwords below handy to take out\n",
    "new_stoplist = ['https', 'el', 'de', 'co', 'lo', 'que', 'la', 'en', 'con', 'por', 'los', 'un', 'del', 'n', 't']\n",
    "\n",
    "for i in new_stoplist:\n",
    "    stop.append(i)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: x.lower())\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub\\\n",
    "                              (\"https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+\", \"url\", x)) # convert links to \"url\"\n",
    "df[\"text_2\"] = df[\"text\"].apply(lambda x: re.sub(\"[^a-zA-Z@]\", \" \", x)) # remove all but alphabetical keeping \"@\"\n",
    "\n",
    "df[\"text_2\"] = \\\n",
    "    df['text_2'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) # remove stopwords\n",
    "df[\"text_2\"] = df[\"text_2\"].apply(remove_whitespace)  # remove extra whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index('date') \n",
    "\n",
    "dec14_neg = df[(df.index.get_level_values(0) >= '2017-12-14 00:00:00') & \n",
    "   (df.index.get_level_values(0) <= '2017-12-14 23:59:00') & \n",
    "   (df.airline_sentiment == \"negative\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = set(('https', 'el', 'de', 'co', 'lo', 'que', 'la', 'en', 'con', 'por', 'los', 'un', 'del', 'n'))\n",
    "fwc = {'stopwords': STOPWORDS | ignore, **wc}\n",
    "text = dec14_neg['text_2'].str.lower().to_string()\n",
    "wordcloud = WordCloud(**fwc, background_color='white',\n",
    "                        #color_func = 'magma',\n",
    "                        colormap = \"inferno_r\",).generate(''.join(text))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\"\"\"\n",
    "savefig(\"ES_2017_12_14_neg.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None, dpi=500)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec14_neg.text_2.str.split(expand=True).stack().value_counts().head(10) # see most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"norwegianairlines\": 1 row\n",
    "# norwegian: 27\n",
    "# aireurope: 1\n",
    "# aireuropa: 40\n",
    "len(df[df[\"text_2\"].str.contains(\"aireuropa\", case = False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index('date') \n",
    "\n",
    "def create_columns_with_airlines(df):\n",
    "    # a list curated based on word frequencies and search terms for data download\n",
    "    list_of_airlines = [\"iberia\", \"ryanair\", \"jetblue\", \"spanair\", \"vueling\", \"norwegian\", \"aireuropa\"]\n",
    "    for airline in list_of_airlines: \n",
    "        df[airline] = \"\"\n",
    "        for index,row in df.iterrows():\n",
    "            if airline in row[\"text\"].lower():\n",
    "                df.set_value(index,airline,1)\n",
    "            else:\n",
    "                df.set_value(index,airline,0)\n",
    "    df[airline] = df[airline].astype(str).astype(int)\n",
    "create_columns_with_airlines(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines_day = df.resample('D').apply({'iberia':'sum', 'spanair': 'sum', 'jetblue': 'sum',\\\n",
    "                                       'vueling': 'sum', 'ryanair': 'sum', 'norwegian': 'sum', 'aireuropa': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines_day_unstacked = airlines_day.unstack().reset_index()\n",
    "airlines_day_unstacked.rename(columns={'level_0': 'airline', 0: 'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove zeros\n",
    "airlines_day_unstacked = airlines_day_unstacked[(airlines_day_unstacked != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines_day_unstacked[\"date\"] = airlines_day_unstacked[\"date\"].apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pivot = airlines_day_unstacked.pivot(\"airline\", \"date\", \"count\")\n",
    "pivot = pivot.fillna(0) # to remove Nones\n",
    "sns.set(rc={'figure.figsize':(15,5)})\n",
    "cmap1 = mpl.colors.ListedColormap(sns.color_palette(\"pink_r\", 100))\n",
    "\n",
    "ax = sns.heatmap(pivot, cmap = cmap1)\n",
    "#ax = sns.heatmap(pivot)\n",
    "#ax.set_ylabel(\"airline mentions\")\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "plt.yticks(fontsize=14)\n",
    "\"\"\"\n",
    "plt.savefig(\"airlines_by_day_ES.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None, dpi = 600)\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select only that day\n",
    "mask = (df['tweet_created'] > \"Thu Dec 14 00:00:00 +0000 2017\") & (df['tweet_created'] <= \"Thu Dec 14 23:59:59 +0000 2017\")\n",
    "data_2017_12_14 = df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2017_12_14_iberia = data_2017_12_14.loc[data_2017_12_14.text_2.str.contains(\"iberia\", case = False, na = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "data_2017_12_14_iberia[\"text_2\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2017_12_14_iberia_negative = (data_2017_12_14_iberia.\\\n",
    "                                   loc[data_2017_12_14_iberia.airline_sentiment == \"negative\"])[\"text_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2017_12_14_iberia_negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2017_12_14_iberia_negative.reset_index().text_2.str.split(expand=True).stack().value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(text): # optionally add: stopwords=STOPWORDS and change the arg below\n",
    "    ignore = set(('https', 'el', 'de', 'co', 'lo', 'que', 'la', 'en', 'con', 'por', 'los', 'un', 'del', 'iberia', 'vuelo'))\n",
    "    fwc = {'stopwords': STOPWORDS | ignore, **wc}\n",
    "    wordcloud = WordCloud(#relative_scaling = 0.75\n",
    "                        **fwc,\n",
    "                        background_color='white',\n",
    "                        colormap = \"inferno_r\"\n",
    "                        #width=800, height=400\n",
    "                          ).generate(text)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    # EN_2015_02_23_neg_american_tweets_without_strings_american_flights\n",
    "    \"\"\"\n",
    "    savefig(\"ES_2017_12_14_neg_iberia.png\", papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.1,\n",
    "        frameon=None, dpi=500)\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "generate_wordcloud(data_2017_12_14_iberia_negative.str.lower().str.strip().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why tweets contain \"felicidades\"?\n",
    "(data_2017_12_14[data_2017_12_14['text'].str.contains(\"felicidades\", case = False)])[\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why tweets contain \"instantaneamente\"?\n",
    "(data_2017_12_14[data_2017_12_14['text'].str.contains(\"instantaneamente\", case = False)])[\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
